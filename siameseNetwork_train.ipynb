{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFLiEonUv5cv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.utils\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cub25fHUEkVL",
        "outputId": "f1f2a954-742e-4c77-d266-99f4bbd059fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/phishing1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My Drive/phishing1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdbxmIbuEkwH"
      },
      "outputs": [],
      "source": [
        "#phishing Dataset\n",
        "folder_dataset_test = datasets.ImageFolder(root=\"/content/drive/My Drive/.../\")\n",
        "#training Dataset\n",
        "folder_dataset = datasets.ImageFolder(root=\"/content/drive/My Drive/.../\")\n",
        "#eval Dataset\n",
        "folder_dataset_test_original = datasets.ImageFolder(root=\"/content/drive/My Drive//\")\n",
        "\n",
        "#   highvarietysmalldata\n",
        "#   trusted_list_and_phishing\n",
        "#   trusted_list_1img\n",
        "#training config\n",
        "\n",
        "learningrate = 0.0001\n",
        "epoch = 60\n",
        "batch = 16\n",
        "architecture = \"\"\n",
        "version = 9\n",
        "#txt file\n",
        "txtfile = f'{epoch}epoch_adam{learningrate:.5f}_batch{batch}_{architecture}.txt'\n",
        "\n",
        "#model save name\n",
        "\n",
        "namemodel2save = f'/content/drive/My Drive/.../{epoch}epoch_adam{learningrate:.5f}_batch{batch}_{architecture}.pth'\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JaZWc1Nz07m"
      },
      "outputs": [],
      "source": [
        "# Creating some helper functions\n",
        "def imshow(img, text=None):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "   # plt.figure(figsize=(224,224))\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD1BFFm_z7aj"
      },
      "outputs": [],
      "source": [
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.imageFolderDataset = imageFolderDataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img0_tuple = self.imageFolderDataset.imgs[index]\n",
        "        # print(img0_tuple, \"img tuple\", \"\\n\")\n",
        "        # print(index, \"INDEX\", \"\\n\")\n",
        "        #Choose a random index for the second image\n",
        "        img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "        #print(img1_index, \"img 1 INDEX\", \"\\n\")\n",
        "        #Ensure that the two images are not the same\n",
        "        while img1_index == index:\n",
        "            img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "\n",
        "        img1_tuple = self.imageFolderDataset.imgs[img1_index]\n",
        "\n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "\n",
        "        img0 = img0.convert('RGB')\n",
        "        img1 = img1.convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "\n",
        "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHtkKkyE9BCo"
      },
      "outputs": [],
      "source": [
        "# every possible kombination\n",
        "\n",
        "# class SiameseNetworkDataset(Dataset):\n",
        "#     def __init__(self, imageFolderDataset, transform=None):\n",
        "#         self.imageFolderDataset = imageFolderDataset\n",
        "#         self.transform = transform\n",
        "\n",
        "#         # Erstellen einer Liste aller möglichen Bildkombinationen\n",
        "#         self.pairs = []\n",
        "#         for i in range(len(self.imageFolderDataset.imgs)):\n",
        "#             for j in range(len(self.imageFolderDataset.imgs)):\n",
        "#                 if i != j:\n",
        "#                     self.pairs.append((i, j))\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         # Auswahl der Indexe der beiden Bilder aus der vorher erstellten Liste\n",
        "\n",
        "#         if index >= len(self.pairs):\n",
        "#             raise IndexError(\"Index out of range.\")\n",
        "\n",
        "#         img0_index, img1_index = self.pairs[index]\n",
        "\n",
        "#         img0_tuple = self.imageFolderDataset.imgs[img0_index]\n",
        "#         img1_tuple = self.imageFolderDataset.imgs[img1_index]\n",
        "\n",
        "#         #print(f\"Image 0 path: {img0_tuple[0]}\")\n",
        "\n",
        "#         #print(f\"Image 1 path: {img1_tuple[0]}\")\n",
        "#         img0 = Image.open(img0_tuple[0])\n",
        "#         img1 = Image.open(img1_tuple[0])\n",
        "\n",
        "#         img0 = img0.convert('RGB')\n",
        "#         img1 = img1.convert('RGB')\n",
        "\n",
        "\n",
        "\n",
        "#         # Ausgabe des extrahierten Texts\n",
        "\n",
        "#         if self.transform is not None:\n",
        "#             img0 = self.transform(img0)\n",
        "#             img1 = self.transform(img1)\n",
        "#         label = torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
        "\n",
        "#         # if label == 0:\n",
        "#         #     print(\"Bilder stellen die gleiche Person dar.\")\n",
        "#         # else:\n",
        "#         #     print(\"Bilder stellen unterschiedliche Personen dar.\")\n",
        "#         return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
        "\n",
        "#     def __len__(self):\n",
        "#         # Die Länge der Liste der Paare ist die Anzahl aller möglichen Kombinationen\n",
        "#         return len(self.pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs_nNlwAaj6o"
      },
      "source": [
        "Download the dataset from our [GitHub](https://github.com/maticvl/dataHacker/blob/master/DATA/at%26t.zip) profile, just by running the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qzYA7F10Cnk"
      },
      "outputs": [],
      "source": [
        "# Resize the images and transform to tensors\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "transformation = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                    ])\n",
        "\n",
        "            # tv.transforms.Resize((224, 224)),\n",
        "            # tv.transforms.RandomCrop((224, 224)),\n",
        "            # tv.transforms.RandomHorizontalFlip(),\n",
        "            # tv.transforms.ToTensor(),\n",
        "            # tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "\n",
        "# Initialize the network\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
        "                                        transform=transformation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUpWDaB3qHi0"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKwASN1g1vhF"
      },
      "outputs": [],
      "source": [
        "# Create a simple dataloader just for simple visualization\n",
        "vis_dataloader = DataLoader(siamese_dataset,\n",
        "                        shuffle=False,\n",
        "                        num_workers=2,\n",
        "                        batch_size=8)\n",
        "\n",
        "# Extract one batch\n",
        "example_batch = next(iter(vis_dataloader))\n",
        "\n",
        "# Example batch is a list containing 2x8 images, indexes 0 and 1, an also the label\n",
        "# If the label is 1, it means that it is not the same person, label is 0, same person in both images\n",
        "concatenated = torch.cat((example_batch[0], example_batch[1]),0)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "print(example_batch[2].numpy().reshape(-1))\n",
        "# picture = torchvision.utils.make_grid(example_batch[1])\n",
        "# extractedInformation = pytesseract.image_to_string(Image.open(example_batch[1]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsfTrqNNu8L_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6laBT-7DyeE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgVfwTo81PqA"
      },
      "outputs": [],
      "source": [
        "# #create the Siamese Neural Network\n",
        "# #Datahacker\n",
        "class SiameseNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11,stride=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 384, kernel_size=3,stride=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Setting up the Fully Connected Layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(31104, 9096),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(9096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(256,2)\n",
        "\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        # This function will be called for both images\n",
        "        # It's output is used to determine the similiarity\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # In this function we pass in both images and obtain both vectors\n",
        "        # which are returned\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "\n",
        "        return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmiF2qIGYLFa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy8IyXebxWGL"
      },
      "outputs": [],
      "source": [
        "# #AlexNet\n",
        "# #https://gist.github.com/bigsnarfdude/f90b7a3bc6965ffc4c5e89e1d6a6c7b0\n",
        "# #create the Siamese Neural Network\n",
        "# class SiameseNetwork(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(SiameseNetwork, self).__init__()\n",
        "\n",
        "#         # Setting up the Sequential of CNN Layers\n",
        "#         self.cnn1 = nn.Sequential(\n",
        "#             nn.Conv2d(3, 64, kernel_size=10, stride=2, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "#         )\n",
        "\n",
        "\n",
        "#         # Setting up the Fully Connected Layers\n",
        "#         self.fc1 = nn.Sequential(\n",
        "\n",
        "\n",
        "#           #(1x9216 and 12544x512)\n",
        "#           #Ram durch viel zu groß\n",
        "\n",
        "#              nn.Linear(43264 , 512),\n",
        "#              nn.ReLU(inplace=True),\n",
        "#              nn.Linear(512, 256),\n",
        "#              nn.ReLU(inplace=True),\n",
        "#              nn.Linear(256, 2)\n",
        "#         )\n",
        "\n",
        "#     def forward_once(self, x):\n",
        "#         # This function will be called for both images\n",
        "#         # It's output is used to determine the similiarity\n",
        "#         output = self.cnn1(x)\n",
        "#         output = output.view(output.size()[0], -1)\n",
        "#         output = self.fc1(output)\n",
        "#         return output\n",
        "\n",
        "#     def forward(self, input1, input2):\n",
        "#         # In this function we pass in both images and obtain both vectors\n",
        "#         # which are returned\n",
        "#         output1 = self.forward_once(input1)\n",
        "#         output2 = self.forward_once(input2)\n",
        "\n",
        "#         return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydgjTdbK2Cha"
      },
      "outputs": [],
      "source": [
        "# Define the Contrastive Loss Function\n",
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "      # Calculate the euclidian distance and calculate the contrastive loss\n",
        "      euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "\n",
        "      loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "\n",
        "      return loss_contrastive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWRvoW8X2Cm5"
      },
      "outputs": [],
      "source": [
        "# Load the training dataset\n",
        "train_dataloader = DataLoader(siamese_dataset,\n",
        "                        shuffle=False,\n",
        "                        num_workers=8,\n",
        "                        batch_size=batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvNMkG8E2FEm"
      },
      "outputs": [],
      "source": [
        "net = SiameseNetwork().cuda()\n",
        "criterion = ContrastiveLoss()\n",
        "optimizer = optim.Adam(net.parameters(),learningrate)\n",
        "#net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7bz8o__2JKn"
      },
      "outputs": [],
      "source": [
        "counter = []\n",
        "loss_history = []\n",
        "iteration_number= 0\n",
        "\n",
        "# Iterate throught the epochs\n",
        "for epoch in range(epoch):\n",
        "\n",
        "    # Iterate over batches\n",
        "    for i, (img0, img1, label) in enumerate(train_dataloader, 0):\n",
        "\n",
        "        # Send the images and labels to CUDA\n",
        "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass in the two images into the network and obtain two outputs\n",
        "        output1, output2 = net(img0, img1)\n",
        "\n",
        "        # Pass the outputs of the networks and label into the loss function\n",
        "        loss_contrastive = criterion(output1, output2, label)\n",
        "\n",
        "        # Calculate the backpropagation\n",
        "        loss_contrastive.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "        # Every 10 batches print out the loss\n",
        "        if i % 10 == 0 :\n",
        "            print(f\"Epoch number {epoch}\\n Current loss {loss_contrastive.item()}\\n\")\n",
        "            iteration_number += 10\n",
        "\n",
        "            counter.append(iteration_number)\n",
        "            loss_history.append(loss_contrastive.item())\n",
        "\n",
        "show_plot(counter, loss_history)\n",
        "torch.save(net.state_dict(), namemodel2save)\n",
        "\n",
        "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
        "\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
        "                                        transform=transformation)\n",
        "test_dataloader = DataLoader(siamese_dataset, num_workers=2, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
        "\n",
        "siamese_dataset_original = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test_original,\n",
        "                                        transform=transformation)\n",
        "test_dataloader_original = DataLoader(siamese_dataset_original, num_workers=2, batch_size=1, shuffle=False)\n",
        "\n",
        "# Grab one image that we are going to test\n",
        "dataiter = iter(test_dataloader)\n",
        "dataiter_ori = iter(test_dataloader_original)\n",
        "file = open(txtfile, 'w')\n",
        "\n",
        "for trusted1, _, _ in dataiter_ori:\n",
        "    for x1, _, _ in test_dataloader:\n",
        "\n",
        "      concatenated = torch.cat((trusted1, x1), 0)\n",
        "\n",
        "      output1, output2 = net(trusted1.cuda(), x1.cuda())\n",
        "      euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "      distance = f' {euclidean_distance.item():.2f}'\n",
        "      #file.write(str(distance) + '\\n')\n",
        "      file.write(str(distance).replace('.', ',') + '\\n')\n",
        "      #imshow(torchvision.utils.make_grid(concatenated), f'Dissimilarity: {euclidean_distance.item():.2f}')\n",
        "\n",
        "file.close()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
