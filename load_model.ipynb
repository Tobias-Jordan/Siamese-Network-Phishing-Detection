{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxiJdNjqeFd4"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.utils\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "import shutil\n",
        "import torchvision.transforms as T\n",
        "import csv\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "\n",
        "# from googletrans import Translator, constants\n",
        "# from pprint import pprint\n",
        "# import pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tw_Dvh9eFq5",
        "outputId": "9eb28e68-3e0f-4afa-ca3d-bb81c15318cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/phishing1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My Drive/phishing1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCQzSuSNxVyw"
      },
      "outputs": [],
      "source": [
        "# #OCR\n",
        "# !pip3 install googletrans\n",
        "# !pip3 install googletrans==3.1.0a0\n",
        "# !sudo apt install tesseract-ocr\n",
        "# !pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKMSuZfsHEOB"
      },
      "outputs": [],
      "source": [
        "# #create the Siamese Neural Network Datahacker mit Layeranpassung\n",
        "# class SiameseNetwork(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(SiameseNetwork, self).__init__()\n",
        "\n",
        "#         self.cnn1 = nn.Sequential(\n",
        "#             nn.Conv2d(3, 96, kernel_size=11,stride=4),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(3, stride=2),\n",
        "\n",
        "#             nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "#             nn.Conv2d(256, 384, kernel_size=3,stride=1),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "\n",
        "#         # Setting up the Fully Connected Layers\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(31104, 9096),\n",
        "#             nn.ReLU(inplace=True),\n",
        "\n",
        "#             nn.Linear(9096, 1024),\n",
        "#             nn.ReLU(inplace=True),\n",
        "\n",
        "#             nn.Linear(1024, 256),\n",
        "#             nn.ReLU(inplace=True),\n",
        "\n",
        "#             nn.Linear(256,2)\n",
        "\n",
        "\n",
        "#         )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     def forward_once(self, x):\n",
        "#         # This function will be called for both images\n",
        "#         # It's output is used to determine the similiarity\n",
        "#         output = self.cnn1(x)\n",
        "#         output = output.view(output.size()[0], -1)\n",
        "#         output = self.fc1(output)\n",
        "#         return output\n",
        "\n",
        "#     def forward(self, input1, input2):\n",
        "#         # In this function we pass in both images and obtain both vectors\n",
        "#         # which are returned\n",
        "#         output1 = self.forward_once(input1)\n",
        "#         output2 = self.forward_once(input2)\n",
        "\n",
        "#         return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtJyKHhFHEj5"
      },
      "outputs": [],
      "source": [
        "# #AlexNet\n",
        "# #https://gist.github.com/bigsnarfdude/f90b7a3bc6965ffc4c5e89e1d6a6c7b0\n",
        "# #create the Siamese Neural Network\n",
        "# class SiameseNetwork(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(SiameseNetwork, self).__init__()\n",
        "\n",
        "#         # Setting up the Sequential of CNN Layers\n",
        "#         self.cnn1 = nn.Sequential(\n",
        "#             nn.Conv2d(3, 64, kernel_size=10, stride=2, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "#         )\n",
        "\n",
        "\n",
        "#         # Setting up the Fully Connected Layers\n",
        "#         self.fc1 = nn.Sequential(\n",
        "\n",
        "\n",
        "#           #(1x9216 and 12544x512)\n",
        "#           #Ram durch viel zu gro√ü\n",
        "\n",
        "#              nn.Linear(43264 , 512),\n",
        "#              nn.ReLU(inplace=True),\n",
        "#              nn.Linear(512, 256),\n",
        "#              nn.ReLU(inplace=True),\n",
        "#              nn.Linear(256, 2)\n",
        "#         )\n",
        "\n",
        "#     def forward_once(self, x):\n",
        "#         # This function will be called for both images\n",
        "#         # It's output is used to determine the similiarity\n",
        "#         output = self.cnn1(x)\n",
        "#         output = output.view(output.size()[0], -1)\n",
        "#         output = self.fc1(output)\n",
        "#         return output\n",
        "\n",
        "#     def forward(self, input1, input2):\n",
        "#         # In this function we pass in both images and obtain both vectors\n",
        "#         # which are returned\n",
        "#         output1 = self.forward_once(input1)\n",
        "#         output2 = self.forward_once(input2)\n",
        "\n",
        "#         return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6shNy4SeFxT",
        "outputId": "3aa83db1-cd82-40d2-9cc1-9d4c348bb05a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['cnn1.0.weight', 'cnn1.0.bias', 'cnn1.3.weight', 'cnn1.3.bias', 'cnn1.6.weight', 'cnn1.6.bias', 'cnn1.9.weight', 'cnn1.9.bias', 'fc1.0.weight', 'fc1.0.bias', 'fc1.2.weight', 'fc1.2.bias', 'fc1.4.weight', 'fc1.4.bias'])\n"
          ]
        }
      ],
      "source": [
        "#60epoch_adam0.00010_batch16_Datahackertrusted_list_1img\n",
        "#60epoch_adam0.00010_batch16_Alexnettrusted_list_1img\n",
        "\n",
        "state_dict = torch.load('/content/drive/My Drive/.pth')\n",
        "print(state_dict.keys())\n",
        "model = SiameseNetwork().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eptF3ffReF0b",
        "outputId": "2ae12b5c-9453-4193-e0b8-efaba656cf9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqPSPGHSndgE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ubu_cS-Dwm4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZPZRodVGrUX"
      },
      "outputs": [],
      "source": [
        "# class SiameseNetworkDataset(Dataset):\n",
        "#     def __init__(self,imageFolderDataset,transform=None):\n",
        "#         self.imageFolderDataset = imageFolderDataset\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __getitem__(self,index):\n",
        "#         img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "\n",
        "#         #We need to approximately 50% of images to be in the same class\n",
        "#         should_get_same_class = random.randint(0,1)\n",
        "#         if should_get_same_class:\n",
        "#             while True:\n",
        "#                 #Look untill the same class image is found\n",
        "#                 img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "#                 if img0_tuple[1] == img1_tuple[1]:\n",
        "#                     break\n",
        "#         else:\n",
        "\n",
        "#             while True:\n",
        "#                 #Look untill a different class image is found\n",
        "#                 img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "#                 if img0_tuple[1] != img1_tuple[1]:\n",
        "#                     break\n",
        "\n",
        "#         img0 = Image.open(img0_tuple[0])\n",
        "#         img1 = Image.open(img1_tuple[0])\n",
        "# #ausprobieren mit in grau umwandeln und dann in rgb\n",
        "#         img0 = img0.convert('RGB')\n",
        "#         img1 = img1.convert('RGB')\n",
        "\n",
        "#         if self.transform is not None:\n",
        "#             img0 = self.transform(img0)\n",
        "#             img1 = self.transform(img1)\n",
        "\n",
        "#         return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj8YPZm1EFH1"
      },
      "outputs": [],
      "source": [
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.imageFolderDataset = imageFolderDataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img0_tuple = self.imageFolderDataset.imgs[index]\n",
        "        # print(img0_tuple, \"img tuple\", \"\\n\")\n",
        "        # print(index, \"INDEX\", \"\\n\")\n",
        "        #Choose a random index for the second image\n",
        "        img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "        #print(img1_index, \"img 1 INDEX\", \"\\n\")\n",
        "        #Ensure that the two images are not the same\n",
        "        while img1_index == index:\n",
        "            img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "\n",
        "        img1_tuple = self.imageFolderDataset.imgs[img1_index]\n",
        "\n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "\n",
        "        img0 = img0.convert('RGB')\n",
        "        img1 = img1.convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "\n",
        "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDhYUDcWEFQ9",
        "outputId": "9c8e52b9-a4ed-4645-99b8-2fce430ec5a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOWtnLgMFVIm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV4bppHhJgjf"
      },
      "outputs": [],
      "source": [
        "# class SiameseNetworkDataset(Dataset):\n",
        "#     def __init__(self,imageFolderDataset,transform=None):\n",
        "#         self.imageFolderDataset = imageFolderDataset\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __getitem__(self,index):\n",
        "#         img0_tuple = self.imageFolderDataset.imgs[index]\n",
        "\n",
        "#         #Choose a random index for the second image\n",
        "#         img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "\n",
        "#         #Ensure that the two images are not the same\n",
        "#         while img1_index == index:\n",
        "#             img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "\n",
        "#         img1_tuple = self.imageFolderDataset.imgs[img1_index]\n",
        "\n",
        "#         img0 = Image.open(img0_tuple[0])\n",
        "#         img1 = Image.open(img1_tuple[0])\n",
        "\n",
        "#         img0 = img0.convert('RGB')\n",
        "#         img1 = img1.convert('RGB')\n",
        "\n",
        "#         if self.transform is not None:\n",
        "#             img0 = self.transform(img0)\n",
        "#             img1 = self.transform(img1)\n",
        "\n",
        "#         return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PssLNlzGnnxi"
      },
      "outputs": [],
      "source": [
        "folder_dataset = datasets.ImageFolder(root=\"/content/drive/My Drive/.../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r7YzR7SnkSj"
      },
      "outputs": [],
      "source": [
        "# Resize the images and transform to tensors\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "transformation = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                    ])\n",
        "\n",
        "            # tv.transforms.Resize((224, 224)),\n",
        "            # tv.transforms.RandomCrop((224, 224)),\n",
        "            # tv.transforms.RandomHorizontalFlip(),\n",
        "            # tv.transforms.ToTensor(),\n",
        "            # tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "\n",
        "# Initialize the network\n",
        "#siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
        "                                       # transform=transformation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHlh0wIV0jmR"
      },
      "outputs": [],
      "source": [
        "# Creating some helper functions\n",
        "def imshow(img, text=None):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    #plt.figure(figsize=(40,40))\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXQ1IZ5ieF6I"
      },
      "outputs": [],
      "source": [
        "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
        "folder_dataset_test = datasets.ImageFolder(root=\"/content/drive/My Drive/.../\")\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
        "                                        transform=transformation)\n",
        "test_dataloader = DataLoader(siamese_dataset, num_workers=2, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
        "folder_dataset_test_original = datasets.ImageFolder(root=\"/content/drive/My Drive/.../\")\n",
        "siamese_dataset_original = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test_original,\n",
        "                                        transform=transformation)\n",
        "test_dataloader_original = DataLoader(siamese_dataset_original, num_workers=2, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(folder_dataset_test)\n",
        "print(folder_dataset_test_original)\n",
        "#\n",
        "\n",
        "\n",
        "# Grab one image that we are going to test\n",
        "dataiter = iter(test_dataloader)\n",
        "dataiter_ori = iter(test_dataloader_original)\n",
        "file = open('60epoch_adam0.00010_batch16_Alexnet_Alibaba.txt', 'w')\n",
        "\n",
        "\n",
        "for trusted1, _, _ in dataiter_ori:\n",
        "    print(1)\n",
        "\n",
        "    for x1, _, _ in test_dataloader:\n",
        "\n",
        "      concatenated = torch.cat((trusted1, x1), 0)\n",
        "\n",
        "\n",
        "\n",
        "      output1, output2 = model(trusted1.cuda(), x1.cuda())\n",
        "\n",
        "      euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "\n",
        "      distance = f' {euclidean_distance.item():.2f}'\n",
        "\n",
        "\n",
        "      #img = transtoimg(x1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      #image = img.convert('RGB')\n",
        "      #extracted_information = pytesseract.image_to_string(image)\n",
        "      #print(extracted_information)\n",
        "      #file.write(str(distance) + '\\n')\n",
        "      file.write(str(distance).replace('.', ',') + '\\n')\n",
        "      imshow(torchvision.utils.make_grid(concatenated), f'Dissimilarity: {euclidean_distance.item():.2f}')\n",
        "\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNg-GdBJhpTc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAzIO8qkKAw8"
      },
      "outputs": [],
      "source": [
        "# # Locate the test dataset and load it into the SiameseNetworkDataset\n",
        "# folder_dataset_test = datasets.ImageFolder(root=\"/content/drive/My Drive/phishing1/nontrusted_list_10classes/\")\n",
        "# siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
        "#                                         transform=transformation)\n",
        "# test_dataloader = DataLoader(siamese_dataset, num_workers=2, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "# # Locate the test dataset and load it into the SiameseNetworkDataset\n",
        "# folder_dataset_test_original = datasets.ImageFolder(root=\"/content/drive/My Drive/phishing1/eval_alibaba/\")\n",
        "# siamese_dataset_original = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test_original,\n",
        "#                                         transform=transformation)\n",
        "# test_dataloader_original = DataLoader(siamese_dataset_original, num_workers=2, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "# # Grab one image that we are going to test\n",
        "# dataiter = iter(test_dataloader)\n",
        "# dataiter_ori = iter(test_dataloader_original)\n",
        "# file = open('60epoch_adam0.00010_batch16_Alexnet_Alibaba.txt', 'w')\n",
        "\n",
        "\n",
        "\n",
        "# for trusted1, _, _ in dataiter_ori:\n",
        "#     for x1, _, _ in test_dataloader:\n",
        "\n",
        "#       concatenated = torch.cat((trusted1, x1), 0)\n",
        "\n",
        "#       output1, output2 = model(trusted1.cuda(), x1.cuda())\n",
        "\n",
        "#       euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "#       distance = f' {euclidean_distance.item():.2f}'\n",
        "#       #file.write(str(distance) + '\\n')\n",
        "#       file.write(str(distance).replace('.', ',') + '\\n')\n",
        "#       imshow(torchvision.utils.make_grid(concatenated), f'Dissimilarity: {euclidean_distance.item():.2f}')\n",
        "\n",
        "# file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FaWux5by4lQ"
      },
      "outputs": [],
      "source": [
        "# folder_dataset = datasets.ImageFolder(root=\"/content/drive/My Drive/phishing1/nontrusted_list_10classes/\")\n",
        "# #OCR Tesseract\n",
        "# translator = Translator()\n",
        "# txtfile = 'ocr_nontrusted_list_10classes.txt'\n",
        "# file = open(txtfile, 'w')\n",
        "# file.write(\"email;password;sign in;brand\"+ '\\n')\n",
        "\n",
        "# for img, _ in folder_dataset:\n",
        "\n",
        "#     # Verwendung des Bildes f√ºr OCR\n",
        "#     extracted_information = pytesseract.image_to_string(img)\n",
        "\n",
        "\n",
        "#     translation = translator.translate(extracted_information)\n",
        "#     print(f\"{translation.origin} ({translation.src}) --> {translation.text} ({translation.dest})\")\n",
        "#     print(\"Hier src\" +translation.src)\n",
        "#     text = translation.text\n",
        "#     print(\"Hier text\" + text + \"\\n\")\n",
        "#     file.write(str((int(\"email\".lower() in text.lower()or \"username\".lower() in text.lower() or \"User ID\".lower() in text.lower() or \"account name\".lower() in text.lower()))) + \";\")\n",
        "#     file.write(str(int(\"password\".lower() in text.lower()))+ \";\")\n",
        "#     file.write(str(int(\"sign in\".lower() in text.lower() or \"log in\".lower() in text.lower()))+ \";\")\n",
        "\n",
        "\n",
        "\n",
        "#     brand = ['alibaba', 'amazon', 'American Express', 'apple', 'chase', 'facebook', 'instagram', 'linkedin', 'paypal', 'steam']\n",
        "#     found_brands = [keyword for keyword in brand if keyword.lower() in text.lower()]\n",
        "\n",
        "#     if found_brands:\n",
        "\n",
        "#         for brand in found_brands:\n",
        "#             file.write(str(brand)+ '\\n')\n",
        "#     else:\n",
        "#         file.write(\"no brand\"+ '\\n')\n",
        "\n",
        "# file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs5txUQg7hHn"
      },
      "outputs": [],
      "source": [
        "# text = textall\n",
        "# txtfile = 'ocr_10classes.txt'\n",
        "# file = open(txtfile, 'w')\n",
        "# file.write(\"email;password;sign in;brand\"+ '\\n')\n",
        "\n",
        "\n",
        "\n",
        "# print(text)\n",
        "\n",
        "# file.write(str((int(\"email\" in text.lower() or \"account name\" in text.lower()))) + \";\")\n",
        "# file.write(str(int(\"password\" in text.lower()))+ \";\")\n",
        "# file.write(str(int(\"sign in\" in text.lower() or \"log in\" in text.lower()))+ \";\")\n",
        "\n",
        "\n",
        "# brand = ['alibaba', 'amazon', 'amex', 'apple', 'chase', 'facebook', 'instagram', 'linkedin', 'paypal', 'steam']\n",
        "# found_brands = [keyword for keyword in brand if keyword.lower() in text.lower()]\n",
        "\n",
        "# if found_brands:\n",
        "\n",
        "#     for brand in found_brands:\n",
        "#         file.write(str(brand))\n",
        "# else:\n",
        "#     file.write(\"no brand\"+ '\\n')\n",
        "\n",
        "# file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1czxlbNTrvM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZL3naktrrih"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi4sVvvXnjYs"
      },
      "outputs": [],
      "source": [
        "# !pip3 install googletrans==3.1.0a0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ayj11Qf2eKcq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
