{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9NR-62sovBt"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.utils\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sZ-_4afo1YH",
        "outputId": "f88426aa-0183-469d-cf56-4647e40fa2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/phishing1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My Drive/phishing1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zMnhQ9orxkg"
      },
      "outputs": [],
      "source": [
        "#phishing Dataset\n",
        "folder_dataset_test = datasets.ImageFolder(root=\"/content/drive/My Drive/.../\")\n",
        "#training Dataset\n",
        "folder_dataset = datasets.ImageFolder(root=\"/content/drive/My Drive/.../\")\n",
        "#eval Dataset\n",
        "folder_dataset_test_original = datasets.ImageFolder(root=\"/content/drive/My Drive/.../\")\n",
        "\n",
        "# pair_list_file = '/content/drive/My Drive/phishing1/combined.txt'\n",
        "pair_list_file = '/content/drive/My Drive/.../amazon.txt'\n",
        "#   highvarietysmalldata\n",
        "#   trusted_list_and_phishing\n",
        "#   trusted_list_1img\n",
        "#training config\n",
        "\n",
        "learningrate = 0.0001\n",
        "epoch = 30\n",
        "batch = 16\n",
        "architecture = \"\"\n",
        "\n",
        "#txt file\n",
        "txtfile = f'{epoch}epoch_adam{learningrate:.5f}_batch{batch}_{architecture}.txt'\n",
        "\n",
        "\n",
        "namemodel2save = f'/content/drive/My Drive/.../{epoch}epoch_adam{learningrate:.5f}_batch{batch}_{architecture}.pth'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGFfaCewriL5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgBcpS29rfHk"
      },
      "outputs": [],
      "source": [
        "# Creating some helper functions\n",
        "def imshow(img, text=None):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "   # plt.figure(figsize=(224,224))\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLWykvWerSaJ"
      },
      "outputs": [],
      "source": [
        "#wird benötigt für Testdatensatz\n",
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None):\n",
        "        self.imageFolderDataset = imageFolderDataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img0_tuple = self.imageFolderDataset.imgs[index]\n",
        "        # print(img0_tuple, \"img tuple\", \"\\n\")\n",
        "        # print(index, \"INDEX\", \"\\n\")\n",
        "        #Choose a random index for the second image\n",
        "        img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "        #print(img1_index, \"img 1 INDEX\", \"\\n\")\n",
        "        #Ensure that the two images are not the same\n",
        "        while img1_index == index:\n",
        "            img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "\n",
        "        img1_tuple = self.imageFolderDataset.imgs[img1_index]\n",
        "\n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "\n",
        "        img0 = img0.convert('RGB')\n",
        "        img1 = img1.convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "\n",
        "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrS008X1OJtX"
      },
      "outputs": [],
      "source": [
        "class SiameseNetworkDataset1(Dataset):\n",
        "    def __init__(self, pairs_file_path=None, imageFolderDataset=None, transform=None):\n",
        "        if pairs_file_path is not None:\n",
        "            self.pairs = []\n",
        "            with open(pairs_file_path, 'r') as file:\n",
        "                lines = file.readlines()\n",
        "                for line in lines:\n",
        "                    img0_path, img1_path, label = line.strip().split(',')\n",
        "                    self.pairs.append((img0_path, img1_path, int(label)))\n",
        "        elif imageFolderDataset is not None:\n",
        "            self.imageFolderDataset = imageFolderDataset\n",
        "        else:\n",
        "            raise ValueError(\"Either 'pairs_file_path' or 'imageFolderDataset' must be provided.\")\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if hasattr(self, 'pairs'):\n",
        "            img0_path, img1_path, label = self.pairs[index]\n",
        "            img0 = Image.open(img0_path).convert('RGB')\n",
        "            img1 = Image.open(img1_path).convert('RGB')\n",
        "        else:\n",
        "            img0_tuple = self.imageFolderDataset.imgs[index]\n",
        "            img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "            while img1_index == index:\n",
        "                img1_index = random.randint(0, len(self.imageFolderDataset) - 1)\n",
        "            img1_tuple = self.imageFolderDataset.imgs[img1_index]\n",
        "            img0 = Image.open(img0_tuple[0]).convert('RGB')\n",
        "            img1 = Image.open(img1_tuple[0]).convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "\n",
        "        return img1, img0, torch.tensor([label], dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        if hasattr(self, 'pairs'):\n",
        "            return len(self.pairs)\n",
        "        else:\n",
        "            return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7poRHLobrSgb"
      },
      "outputs": [],
      "source": [
        "# Resize the images and transform to tensors\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "transformation = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                    ])\n",
        "\n",
        "            # tv.transforms.Resize((224, 224)),\n",
        "            # tv.transforms.RandomCrop((224, 224)),\n",
        "            # tv.transforms.RandomHorizontalFlip(),\n",
        "            # tv.transforms.ToTensor(),\n",
        "            # tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc7mqGvasO5D"
      },
      "outputs": [],
      "source": [
        "# pair_list_file = '/content/drive/My Drive/phishing1/combined.txt'\n",
        "pair_list_file = '/content/drive/My Drive/phishing1/amazon.txt'\n",
        "siamese_dataset = SiameseNetworkDataset1(pair_list_file, transform=transformation)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctMvIzhprSog"
      },
      "outputs": [],
      "source": [
        "# Create a simple dataloader just for simple visualization\n",
        "vis_dataloader = DataLoader(siamese_dataset,\n",
        "                        shuffle=False,\n",
        "                        num_workers=2,\n",
        "                        batch_size=8)\n",
        "\n",
        "# Extract one batch\n",
        "example_batch = next(iter(vis_dataloader))\n",
        "\n",
        "# Example batch is a list containing 2x8 images, indexes 0 and 1, an also the label\n",
        "# If the label is 1, it means that it is not the same person, label is 0, same person in both images\n",
        "concatenated = torch.cat((example_batch[0], example_batch[1]),0)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "print(example_batch[2].numpy().reshape(-1))\n",
        "# picture = torchvision.utils.make_grid(example_batch[1])\n",
        "# extractedInformation = pytesseract.image_to_string(Image.open(example_batch[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCcW4VoVrMsN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyaZJ2F8rM1z"
      },
      "outputs": [],
      "source": [
        "# #create the Siamese Neural Network Datahacker mit Layeranpassung\n",
        "# class SiameseNetwork(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(SiameseNetwork, self).__init__()\n",
        "\n",
        "#         self.cnn1 = nn.Sequential(\n",
        "#             nn.Conv2d(3, 96, kernel_size=11,stride=4),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(3, stride=2),\n",
        "\n",
        "#             nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "#             nn.Conv2d(256, 384, kernel_size=3,stride=1),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "\n",
        "#         # Setting up the Fully Connected Layers\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(31104, 9096),\n",
        "#             nn.ReLU(inplace=True),\n",
        "\n",
        "#             nn.Linear(9096, 1024),\n",
        "#             nn.ReLU(inplace=True),\n",
        "\n",
        "#             nn.Linear(1024, 256),\n",
        "#             nn.ReLU(inplace=True),\n",
        "\n",
        "#             nn.Linear(256,2)\n",
        "#         )\n",
        "\n",
        "#     def forward_once(self, x):\n",
        "#         # This function will be called for both images\n",
        "#         # It's output is used to determine the similarity\n",
        "#         output = self.cnn1(x)\n",
        "#         output = output.view(output.size()[0], -1)\n",
        "#         output = self.fc1(output)\n",
        "#         return output\n",
        "\n",
        "#     def forward(self, input1, input2):\n",
        "#         # In this function we pass in both images and obtain both vectors\n",
        "#         # which are returned\n",
        "#         output1 = self.forward_once(input1)\n",
        "#         output2 = self.forward_once(input2)\n",
        "\n",
        "#         return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0FPkgwMrXGS"
      },
      "outputs": [],
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=10, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Dropout(0.25),  # Beispielwert, du kannst die Dropout-Rate anpassen\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=7, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=4, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(12544, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "            nn.Linear(256, 2)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hv109xGqnJe"
      },
      "outputs": [],
      "source": [
        "# #AlexNet\n",
        "# #https://gist.github.com/bigsnarfdude/f90b7a3bc6965ffc4c5e89e1d6a6c7b0\n",
        "# #create the Siamese Neural Network\n",
        "# class SiameseNetwork(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(SiameseNetwork, self).__init__()\n",
        "\n",
        "#         # Setting up the Sequential of CNN Layers\n",
        "#         self.cnn1 = nn.Sequential(\n",
        "#             nn.Conv2d(3, 64, kernel_size=10, stride=2, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(2, stride=2),\n",
        "#         )\n",
        "\n",
        "\n",
        "#         # Setting up the Fully Connected Layers\n",
        "#         self.fc1 = nn.Sequential(\n",
        "\n",
        "\n",
        "#           #(1x9216 and 12544x512)\n",
        "#           #Ram durch viel zu groß\n",
        "\n",
        "#              nn.Linear(43264 , 512),\n",
        "#              nn.ReLU(inplace=True),\n",
        "#              nn.Linear(512, 256),\n",
        "#              nn.ReLU(inplace=True),\n",
        "#              nn.Linear(256, 2)\n",
        "#         )\n",
        "\n",
        "#     def forward_once(self, x):\n",
        "#         # This function will be called for both images\n",
        "#         # It's output is used to determine the similiarity\n",
        "#         output = self.cnn1(x)\n",
        "#         output = output.view(output.size()[0], -1)\n",
        "#         output = self.fc1(output)\n",
        "#         return output\n",
        "\n",
        "#     def forward(self, input1, input2):\n",
        "#         # In this function we pass in both images and obtain both vectors\n",
        "#         # which are returned\n",
        "#         output1 = self.forward_once(input1)\n",
        "#         output2 = self.forward_once(input2)\n",
        "\n",
        "#         return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuF8HTrQo1iU"
      },
      "outputs": [],
      "source": [
        "# Define the Contrastive Loss Function\n",
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "      # Calculate the euclidian distance and calculate the contrastive loss\n",
        "      euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "\n",
        "      loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "\n",
        "      return loss_contrastive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_s_ANJDo1k3",
        "outputId": "3e646fb9-528d-43e0-ca9e-ac75f744a547"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Load the training dataset\n",
        "train_dataloader = DataLoader(siamese_dataset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=8,\n",
        "                        batch_size=batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIgolpsJo1nM"
      },
      "outputs": [],
      "source": [
        "net = SiameseNetwork().cuda()\n",
        "criterion = ContrastiveLoss()\n",
        "#optimizer = optim.Adam(net.parameters(),learningrate)\n",
        "optimizer = optim.Adam(net.parameters(), learningrate, weight_decay=1e-5)\n",
        "#net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TCcuD1bpo1ph"
      },
      "outputs": [],
      "source": [
        "counter = []\n",
        "loss_history = []\n",
        "iteration_number= 0\n",
        "\n",
        "# Iterate throught the epochs\n",
        "for epoch in range(epoch):\n",
        "\n",
        "    # Iterate over batches\n",
        "    for i, (img0, img1, label) in enumerate(train_dataloader, 0):\n",
        "\n",
        "        # Send the images and labels to CUDA\n",
        "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass in the two images into the network and obtain two outputs\n",
        "        output1, output2 = net(img0, img1)\n",
        "\n",
        "        # Pass the outputs of the networks and label into the loss function\n",
        "        loss_contrastive = criterion(output1, output2, label)\n",
        "\n",
        "        # Calculate the backpropagation\n",
        "        loss_contrastive.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "        # Every 10 batches print out the loss\n",
        "        if i % 10 == 0 :\n",
        "            print(f\"Epoch number {epoch}\\n Current loss {loss_contrastive.item()}\\n\")\n",
        "            iteration_number += 10\n",
        "\n",
        "            counter.append(iteration_number)\n",
        "            loss_history.append(loss_contrastive.item())\n",
        "\n",
        "show_plot(counter, loss_history)\n",
        "torch.save(net.state_dict(), namemodel2save)\n",
        "\n",
        "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
        "\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
        "                                        transform=transformation)\n",
        "test_dataloader = DataLoader(siamese_dataset, num_workers=2, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
        "\n",
        "siamese_dataset_original = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test_original,\n",
        "                                        transform=transformation)\n",
        "test_dataloader_original = DataLoader(siamese_dataset_original, num_workers=2, batch_size=1, shuffle=False)\n",
        "\n",
        "# Grab one image that we are going to test\n",
        "dataiter = iter(test_dataloader)\n",
        "dataiter_ori = iter(test_dataloader_original)\n",
        "file = open(txtfile, 'w')\n",
        "\n",
        "for trusted1, _, _ in dataiter_ori:\n",
        "    for x1, _, _ in test_dataloader:\n",
        "\n",
        "      concatenated = torch.cat((trusted1, x1), 0)\n",
        "\n",
        "      output1, output2 = net(trusted1.cuda(), x1.cuda())\n",
        "      euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "      distance = f' {euclidean_distance.item():.2f}'\n",
        "      #file.write(str(distance) + '\\n')\n",
        "      file.write(str(distance).replace('.', ',') + '\\n')\n",
        "      imshow(torchvision.utils.make_grid(concatenated), f'Dissimilarity: {euclidean_distance.item():.2f}')\n",
        "\n",
        "file.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LfZuOwF8o1r_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zkxq3uoJo1uv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
